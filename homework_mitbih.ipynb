{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from .arff files\n",
    "import os\n",
    "\n",
    "import sktime\n",
    "from sktime.datasets import load_from_tsfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# load data from .csv using pd\n",
    "def load_data(path):\n",
    "\n",
    "    # load data from .csv\n",
    "    data = pd.read_csv(path, header=None)\n",
    "\n",
    "    # get labels\n",
    "    y = data.iloc[:, -1].values\n",
    "\n",
    "    # get features\n",
    "    X = data.iloc[:, :-1].values\n",
    "\n",
    "    # return features and labels\n",
    "    return X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading MITBIH DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mitbih data\n",
    "train_x_mitbih, train_y_mitbih = load_data(\n",
    "    \"./datasets/ecg/mitbih_train.csv\"\n",
    ")\n",
    "test_x_mitbih, test_y_mitbih = load_data(\n",
    "    \"./datasets/ecg/mitbih_test.csv\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading PTBDB DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ptbdb data \n",
    "ptbdb_normal_x, ptbdb_normal_y = load_data(\n",
    "    \"./datasets/ecg/ptbdb_normal.csv\"\n",
    ")\n",
    "\n",
    "ptbdb_abnormal_x, ptbdb_abnormal_y = load_data(\n",
    "    \"./datasets/ecg/ptbdb_abnormal.csv\"\n",
    ")\n",
    "\n",
    "# merge the data and labels\n",
    "x_ptbdb = np.concatenate((ptbdb_normal_x, ptbdb_abnormal_x))\n",
    "y_ptbdb = np.concatenate((ptbdb_normal_y, ptbdb_abnormal_y))\n",
    "\n",
    "# split the data into train and test using \n",
    "train_x_ptbdb, test_x_ptbdb, train_y_ptbdb, test_y_ptbdb = train_test_split(x_ptbdb, y_ptbdb, test_size=0.33, random_state=42)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PTBDB DATA VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data ptbdb\n",
    "\n",
    "# create a dataframe from the data and labels \n",
    "df_train_ptbdb = pd.DataFrame(train_x_ptbdb)\n",
    "df_train_ptbdb['label'] = train_y_ptbdb\n",
    "\n",
    "# create a plot bar from the dataframe using pandas.plot.bar\n",
    "df_train_ptbdb['label'].value_counts().plot.bar(title = \"Train data ptbdb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data ptbdb\n",
    "\n",
    "# create a dataframe from the data and labels \n",
    "df_test_ptbdb = pd.DataFrame(test_x_ptbdb)\n",
    "df_test_ptbdb['label'] = test_y_ptbdb\n",
    "\n",
    "# create a plot bar from the dataframe using pandas.plot.bar\n",
    "df_test_ptbdb['label'].value_counts().plot.bar(title = \"Test data ptbdb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put test_df and train_df on the same plot bar with different colors \n",
    "df_train_ptbdb['label'].value_counts().plot.bar(title = \"Train and Test data ptbdb\", color = 'blue', alpha = 1)\n",
    "df_test_ptbdb['label'].value_counts().plot.bar(color = 'red', alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbdb_labels = df_train_ptbdb['label'].unique()\n",
    "counts_train = df_train_ptbdb['label'].value_counts()\n",
    "counts_test= df_test_ptbdb['label'].value_counts()\n",
    "\n",
    "\n",
    "print(\"----------------------------------\")\n",
    "print(\"TRAIN: \"+  str(counts_train))\n",
    "print(\"----------------------------------\")\n",
    "print(\"TEST: \" + str(counts_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each label, plot the data#\n",
    "for label in ptbdb_labels:\n",
    "    current = df_train_ptbdb[df_train_ptbdb['label'] == label].iloc[0]\n",
    "\n",
    "    # create a dataframe from the data and labels\n",
    "    current_df = pd.DataFrame(current)\n",
    "    current_df = current_df.drop('label', axis = 0)\n",
    "    current_df.plot(title = str(label), figsize = (10, 5))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MITBIH DATA VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data mitbih\n",
    "\n",
    "# create a dataframe from the data and labels \n",
    "train_df_mitbih = pd.DataFrame(train_x_mitbih)\n",
    "train_df_mitbih['label'] = train_y_mitbih\n",
    "\n",
    "# create a plot bar from the dataframe using pandas.plot.bar\n",
    "train_df_mitbih['label'].value_counts().plot.bar(title = \"Train data mitbih\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data mitbih\n",
    "\n",
    "# create a dataframe from the data and labels \n",
    "test_df_mitbih = pd.DataFrame(test_x_mitbih)\n",
    "test_df_mitbih['label'] = test_y_mitbih\n",
    "\n",
    "# create a plot bar from the dataframe using pandas.plot.bar\n",
    "test_df_mitbih['label'].value_counts().plot.bar(title = \"Train data mitbih\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put test_df and train_df on the same plot bar with different colors \n",
    "train_df_mitbih['label'].value_counts().plot.bar(title = \"Train and Test data\", color = 'blue', alpha = 1)\n",
    "test_df_mitbih['label'].value_counts().plot.bar(color = 'red', alpha = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract unique labels from the data\n",
    "mitbih_labels = train_df_mitbih['label'].unique()\n",
    "counts_train = train_df_mitbih['label'].value_counts()\n",
    "counts_test= test_df_mitbih['label'].value_counts()\n",
    "\n",
    "\n",
    "print(mitbih_labels)\n",
    "print(\"----------------------------------\")\n",
    "print(\"TRAIN: \"+  str(counts_train))\n",
    "print(\"----------------------------------\")\n",
    "print(\"TEST: \" + str(counts_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each label, plot the data#\n",
    "for label in mitbih_labels:\n",
    "    current = train_df_mitbih[train_df_mitbih['label'] == label].iloc[0]\n",
    "\n",
    "    # create a dataframe from the data and labels\n",
    "    current_df = pd.DataFrame(current)\n",
    "    current_df = current_df.drop('label', axis = 0)\n",
    "    current_df.plot(title = str(label), figsize = (10, 5))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEDIA SI DEVIATIA STANDARD PER UNITATE DE TIMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Media si deviatia standard pt fiecare label pt mitbih\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "for label in ptbdb_labels:\n",
    "    current = df_train_ptbdb[df_train_ptbdb['label'] == label]\n",
    "\n",
    "    # create a dataframe from the data and labels\n",
    "    current_df = pd.DataFrame(current)\n",
    "    current_df = current_df.drop('label', axis = 1)\n",
    "    current_df_mean = current_df.mean()\n",
    "    current_df_std = current_df.std()\n",
    "    current_df_mean.plot(title = str(label), figsize = (10, 5))\n",
    "    current_df_std.plot(title = str(label), figsize = (10, 5))\n",
    "\n",
    "    # end plot\n",
    "    plt.legend(['mean', 'std'])\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Media si deviatia standard pt fiecare label pt mitbih\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "for label in mitbih_labels:\n",
    "    current = train_df_mitbih[train_df_mitbih['label'] == label]\n",
    "\n",
    "    # create a dataframe from the data and labels\n",
    "    current_df = pd.DataFrame(current)\n",
    "    current_df = current_df.drop('label', axis = 1)\n",
    "    current_df_mean = current_df.mean()\n",
    "    current_df_std = current_df.std()\n",
    "    current_df_mean.plot(title = str(label), figsize = (10, 5))\n",
    "    current_df_std.plot(title = str(label), figsize = (10, 5))\n",
    "\n",
    "    # end plot\n",
    "    plt.legend(['mean', 'std'])\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.2. Extragerea atributelor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setam atributele default date de intrare MITBIH pentru train\n",
    "X_train_std_mitbih = pd.DataFrame(train_x_mitbih)\n",
    "\n",
    "X_train_std_mitbih\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setam atributele default date de intrare MITBIH pentru test\n",
    "X_test_std_mitbih = pd.DataFrame(test_x_mitbih)\n",
    "\n",
    "X_test_std_mitbih\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setam atributele default date de intrare PTBDB pentru train\n",
    "X_train_std_ptbdb = pd.DataFrame(train_x_ptbdb)\n",
    "\n",
    "X_train_std_ptbdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setam atributele default date de intrare PTBDB pentru test\n",
    "X_test_std_ptbdb = pd.DataFrame(test_x_ptbdb)\n",
    "\n",
    "X_test_std_ptbdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setam atributele statistice date de intrare MITBIH pentru datele de train\n",
    "X_train_statistics_mitbih = pd.DataFrame()\n",
    "\n",
    "# Mean features\n",
    "X_train_statistics_mitbih['mean'] = X_train_std_mitbih.mean(axis=1)\n",
    "\n",
    "# Standard deviation features\n",
    "X_train_statistics_mitbih['std'] = X_train_std_mitbih.std(axis=1)\n",
    "\n",
    "# Average absolute difference features\n",
    "X_train_statistics_mitbih['avg_abs_diff'] = X_train_std_mitbih.mad(axis=1)\n",
    "\n",
    "# Min features\n",
    "X_train_statistics_mitbih['min'] = X_train_std_mitbih.min(axis=1)\n",
    "\n",
    "# Max features\n",
    "X_train_statistics_mitbih['max'] = X_train_std_mitbih.max(axis=1)\n",
    "\n",
    "# Max-min features\n",
    "X_train_statistics_mitbih['max-min'] = X_train_statistics_mitbih['max'] - X_train_statistics_mitbih['min']\n",
    "\n",
    "# Median features\n",
    "X_train_statistics_mitbih['median'] = X_train_std_mitbih.median(axis=1)\n",
    "\n",
    "# Median absolute deviation features, don't use X_train_std_mitbih.mad(axis=1) because it's the average absolute difference\n",
    "# X_train_statistics_mitbih['median_abs_dev'] = (X_train_std_mitbih - X_train_statistics_mitbih['median']).abs().median(axis=1)\n",
    "\n",
    "# Interquartile range features\n",
    "X_train_statistics_mitbih['interquartile_range'] = X_train_std_mitbih.quantile(0.75, axis=1) - X_train_std_mitbih.quantile(0.25, axis=1)\n",
    "\n",
    "# Values above mean features\n",
    "# X_train_statistics_mitbih['values_above_mean'] = (X_train_std_mitbih > X_train_statistics_mitbih['mean']).sum(axis=1)\n",
    "\n",
    "# Number of peaks features\n",
    "# X_train_statistics_mitbih['number_of_peaks'] = (X_train_std_mitbih.diff(axis=1) < 0).sum(axis=1)\n",
    "\n",
    "# Skewnness features\n",
    "X_train_statistics_mitbih['skewness'] = X_train_std_mitbih.skew(axis=1)\n",
    "\n",
    "# Kurtosis features\n",
    "X_train_statistics_mitbih['kurtosis'] = X_train_std_mitbih.kurtosis(axis=1)\n",
    "\n",
    "# Energy features\n",
    "X_train_statistics_mitbih['energy'] = (X_train_std_mitbih ** 2).sum(axis=1)\n",
    "\n",
    "# Average of absolute values features\n",
    "X_train_statistics_mitbih['avg_abs_val'] = X_train_std_mitbih.abs().mean(axis=1)\n",
    "\n",
    "# Signal magnitude area features\n",
    "X_train_statistics_mitbih['signal_magnitude_area'] = X_train_std_mitbih.abs().sum(axis=1)\n",
    "\n",
    "# Compute FFT features\n",
    "fft = np.abs(np.fft.fft(X_train_std_mitbih))\n",
    "\n",
    "# make fft data frame\n",
    "fft = pd.DataFrame(fft)\n",
    "\n",
    "# FFT mean features\n",
    "X_train_statistics_mitbih['fft_mean'] = fft.mean(axis=1)\n",
    "\n",
    "# FFT standard deviation features\n",
    "X_train_statistics_mitbih['fft_std'] = fft.std(axis=1)\n",
    "\n",
    "# FFT average absolute difference features\n",
    "X_train_statistics_mitbih['fft_avg_abs_diff'] = fft.mad(axis=1)\n",
    "\n",
    "# FFT min features\n",
    "X_train_statistics_mitbih['fft_min'] = fft.min(axis=1)\n",
    "\n",
    "# FFT max features\n",
    "X_train_statistics_mitbih['fft_max'] = fft.max(axis=1)\n",
    "\n",
    "# FFT max-min features\n",
    "X_train_statistics_mitbih['fft_max-min'] = X_train_statistics_mitbih['fft_max'] - X_train_statistics_mitbih['fft_min']\n",
    "\n",
    "# FFT median features\n",
    "X_train_statistics_mitbih['fft_median'] = fft.median(axis=1)\n",
    "\n",
    "# FFT median absolute deviation features, don't use fft.mad(axis=1) because it's the average absolute difference\n",
    "# X_train_statistics_mitbih['fft_median_abs_dev'] = (fft - X_train_statistics_mitbih['fft_median']).abs().median(axis=1)\n",
    "\n",
    "# FFT interquartile range features\n",
    "X_train_statistics_mitbih['fft_interquartile_range'] = fft.quantile(0.75, axis=1) - fft.quantile(0.25, axis=1)\n",
    "\n",
    "# FFT values above mean features\n",
    "# X_train_statistics_mitbih['fft_values_above_mean'] = (fft > X_train_statistics_mitbih['fft_mean']).sum(axis=1)\n",
    "\n",
    "# FFT number of peaks features\n",
    "# X_train_statistics_mitbih['fft_number_of_peaks'] = (fft.diff(axis=1) < 0).sum(axis=1)\n",
    "\n",
    "# FFT skewnness features\n",
    "X_train_statistics_mitbih['fft_skewness'] = fft.skew(axis=1)\n",
    "\n",
    "# FFT kurtosis features\n",
    "X_train_statistics_mitbih['fft_kurtosis'] = fft.kurtosis(axis=1)\n",
    "\n",
    "# FFT energy features\n",
    "X_train_statistics_mitbih['fft_energy'] = (fft ** 2).sum(axis=1)\n",
    "\n",
    "# FFT average of absolute values features\n",
    "X_train_statistics_mitbih['fft_avg_abs_val'] = fft.abs().mean(axis=1)\n",
    "\n",
    "# FFT signal magnitude area features\n",
    "X_train_statistics_mitbih['fft_signal_magnitude_area'] = fft.abs().sum(axis=1)\n",
    "\n",
    "X_train_statistics_mitbih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setam atributele statistice date de intrare ptbdb pentru datele de train\n",
    "X_train_statistics_ptbdb = pd.DataFrame()\n",
    "\n",
    "# Mean features\n",
    "X_train_statistics_ptbdb['mean'] = X_train_std_ptbdb.mean(axis=1)\n",
    "\n",
    "# Standard deviation features\n",
    "X_train_statistics_ptbdb['std'] = X_train_std_ptbdb.std(axis=1)\n",
    "\n",
    "# Average absolute difference features\n",
    "X_train_statistics_ptbdb['avg_abs_diff'] = X_train_std_ptbdb.mad(axis=1)\n",
    "\n",
    "# Min features\n",
    "X_train_statistics_ptbdb['min'] = X_train_std_ptbdb.min(axis=1)\n",
    "\n",
    "# Max features\n",
    "X_train_statistics_ptbdb['max'] = X_train_std_ptbdb.max(axis=1)\n",
    "\n",
    "# Max-min features\n",
    "X_train_statistics_ptbdb['max-min'] = X_train_statistics_ptbdb['max'] - X_train_statistics_ptbdb['min']\n",
    "\n",
    "# Median features\n",
    "X_train_statistics_ptbdb['median'] = X_train_std_ptbdb.median(axis=1)\n",
    "\n",
    "# Median absolute deviation features, don't use X_train_std_ptbdb.mad(axis=1) because it's the average absolute difference\n",
    "# X_train_statistics_ptbdb['median_abs_dev'] = (X_train_std_ptbdb - X_train_statistics_ptbdb['median']).abs().median(axis=1)\n",
    "\n",
    "# Interquartile range features\n",
    "X_train_statistics_ptbdb['interquartile_range'] = X_train_std_ptbdb.quantile(0.75, axis=1) - X_train_std_ptbdb.quantile(0.25, axis=1)\n",
    "\n",
    "# Values above mean features\n",
    "# X_train_statistics_ptbdb['values_above_mean'] = (X_train_std_ptbdb > X_train_statistics_ptbdb['mean']).sum(axis=1)\n",
    "\n",
    "# Number of peaks features\n",
    "# X_train_statistics_ptbdb['number_of_peaks'] = (X_train_std_ptbdb.diff(axis=1) < 0).sum(axis=1)\n",
    "\n",
    "# Skewnness features\n",
    "X_train_statistics_ptbdb['skewness'] = X_train_std_ptbdb.skew(axis=1)\n",
    "\n",
    "# Kurtosis features\n",
    "X_train_statistics_ptbdb['kurtosis'] = X_train_std_ptbdb.kurtosis(axis=1)\n",
    "\n",
    "# Energy features\n",
    "X_train_statistics_ptbdb['energy'] = (X_train_std_ptbdb ** 2).sum(axis=1)\n",
    "\n",
    "# Average of absolute values features\n",
    "X_train_statistics_ptbdb['avg_abs_val'] = X_train_std_ptbdb.abs().mean(axis=1)\n",
    "\n",
    "# Signal magnitude area features\n",
    "X_train_statistics_ptbdb['signal_magnitude_area'] = X_train_std_ptbdb.abs().sum(axis=1)\n",
    "\n",
    "# Compute FFT features\n",
    "fft = np.abs(np.fft.fft(X_train_std_ptbdb))\n",
    "\n",
    "# make fft data frame\n",
    "fft = pd.DataFrame(fft)\n",
    "\n",
    "# FFT mean features\n",
    "X_train_statistics_ptbdb['fft_mean'] = fft.mean(axis=1)\n",
    "\n",
    "# FFT standard deviation features\n",
    "X_train_statistics_ptbdb['fft_std'] = fft.std(axis=1)\n",
    "\n",
    "# FFT average absolute difference features\n",
    "X_train_statistics_ptbdb['fft_avg_abs_diff'] = fft.mad(axis=1)\n",
    "\n",
    "# FFT min features\n",
    "X_train_statistics_ptbdb['fft_min'] = fft.min(axis=1)\n",
    "\n",
    "# FFT max features\n",
    "X_train_statistics_ptbdb['fft_max'] = fft.max(axis=1)\n",
    "\n",
    "# FFT max-min features\n",
    "X_train_statistics_ptbdb['fft_max-min'] = X_train_statistics_ptbdb['fft_max'] - X_train_statistics_ptbdb['fft_min']\n",
    "\n",
    "# FFT median features\n",
    "X_train_statistics_ptbdb['fft_median'] = fft.median(axis=1)\n",
    "\n",
    "# FFT median absolute deviation features, don't use fft.mad(axis=1) because it's the average absolute difference\n",
    "# X_train_statistics_ptbdb['fft_median_abs_dev'] = (fft - X_train_statistics_ptbdb['fft_median']).abs().median(axis=1)\n",
    "\n",
    "# FFT interquartile range features\n",
    "X_train_statistics_ptbdb['fft_interquartile_range'] = fft.quantile(0.75, axis=1) - fft.quantile(0.25, axis=1)\n",
    "\n",
    "# FFT values above mean features\n",
    "# X_train_statistics_ptbdb['fft_values_above_mean'] = (fft > X_train_statistics_ptbdb['fft_mean']).sum(axis=1)\n",
    "\n",
    "# FFT number of peaks features\n",
    "# X_train_statistics_ptbdb['fft_number_of_peaks'] = (fft.diff(axis=1) < 0).sum(axis=1)\n",
    "\n",
    "# FFT skewnness features\n",
    "X_train_statistics_ptbdb['fft_skewness'] = fft.skew(axis=1)\n",
    "\n",
    "# FFT kurtosis features\n",
    "X_train_statistics_ptbdb['fft_kurtosis'] = fft.kurtosis(axis=1)\n",
    "\n",
    "# FFT energy features\n",
    "X_train_statistics_ptbdb['fft_energy'] = (fft ** 2).sum(axis=1)\n",
    "\n",
    "# FFT average of absolute values features\n",
    "X_train_statistics_ptbdb['fft_avg_abs_val'] = fft.abs().mean(axis=1)\n",
    "\n",
    "# FFT signal magnitude area features\n",
    "X_train_statistics_ptbdb['fft_signal_magnitude_area'] = fft.abs().sum(axis=1)\n",
    "\n",
    "X_train_statistics_ptbdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setam atributele statistice date de intrare MITBIH pentru datele de test\n",
    "X_test_statistics_mitbih = pd.DataFrame()\n",
    "\n",
    "# Mean features\n",
    "X_test_statistics_mitbih['mean'] = X_test_std_mitbih.mean(axis=1)\n",
    "\n",
    "# Standard deviation features\n",
    "X_test_statistics_mitbih['std'] = X_test_std_mitbih.std(axis=1)\n",
    "\n",
    "# Average absolute difference features\n",
    "X_test_statistics_mitbih['avg_abs_diff'] = X_test_std_mitbih.mad(axis=1)\n",
    "\n",
    "# Min features\n",
    "X_test_statistics_mitbih['min'] = X_test_std_mitbih.min(axis=1)\n",
    "\n",
    "# Max features\n",
    "X_test_statistics_mitbih['max'] = X_test_std_mitbih.max(axis=1)\n",
    "\n",
    "# Max-min features\n",
    "X_test_statistics_mitbih['max-min'] = X_test_statistics_mitbih['max'] - X_test_statistics_mitbih['min']\n",
    "\n",
    "# Median features\n",
    "X_test_statistics_mitbih['median'] = X_test_std_mitbih.median(axis=1)\n",
    "\n",
    "# Median absolute deviation features, don't use X_test_std_mitbih.mad(axis=1) because it's the average absolute difference\n",
    "# X_test_statistics_mitbih['median_abs_dev'] = (X_test_std_mitbih - X_test_statistics_mitbih['median']).abs().median(axis=1)\n",
    "\n",
    "# Interquartile range features\n",
    "X_test_statistics_mitbih['interquartile_range'] = X_test_std_mitbih.quantile(0.75, axis=1) - X_test_std_mitbih.quantile(0.25, axis=1)\n",
    "\n",
    "# Values above mean features\n",
    "# X_test_statistics_mitbih['values_above_mean'] = (X_test_std_mitbih > X_test_statistics_mitbih['mean']).sum(axis=1)\n",
    "\n",
    "# Number of peaks features\n",
    "# X_test_statistics_mitbih['number_of_peaks'] = (X_test_std_mitbih.diff(axis=1) < 0).sum(axis=1)\n",
    "\n",
    "# Skewnness features\n",
    "X_test_statistics_mitbih['skewness'] = X_test_std_mitbih.skew(axis=1)\n",
    "\n",
    "# Kurtosis features\n",
    "X_test_statistics_mitbih['kurtosis'] = X_test_std_mitbih.kurtosis(axis=1)\n",
    "\n",
    "# Energy features\n",
    "X_test_statistics_mitbih['energy'] = (X_test_std_mitbih ** 2).sum(axis=1)\n",
    "\n",
    "# Average of absolute values features\n",
    "X_test_statistics_mitbih['avg_abs_val'] = X_test_std_mitbih.abs().mean(axis=1)\n",
    "\n",
    "# Signal magnitude area features\n",
    "X_test_statistics_mitbih['signal_magnitude_area'] = X_test_std_mitbih.abs().sum(axis=1)\n",
    "\n",
    "# Compute FFT features\n",
    "fft = np.abs(np.fft.fft(X_test_std_mitbih))\n",
    "\n",
    "# make fft data frame\n",
    "fft = pd.DataFrame(fft)\n",
    "\n",
    "# FFT mean features\n",
    "X_test_statistics_mitbih['fft_mean'] = fft.mean(axis=1)\n",
    "\n",
    "# FFT standard deviation features\n",
    "X_test_statistics_mitbih['fft_std'] = fft.std(axis=1)\n",
    "\n",
    "# FFT average absolute difference features\n",
    "X_test_statistics_mitbih['fft_avg_abs_diff'] = fft.mad(axis=1)\n",
    "\n",
    "# FFT min features\n",
    "X_test_statistics_mitbih['fft_min'] = fft.min(axis=1)\n",
    "\n",
    "# FFT max features\n",
    "X_test_statistics_mitbih['fft_max'] = fft.max(axis=1)\n",
    "\n",
    "# FFT max-min features\n",
    "X_test_statistics_mitbih['fft_max-min'] = X_test_statistics_mitbih['fft_max'] - X_test_statistics_mitbih['fft_min']\n",
    "\n",
    "# FFT median features\n",
    "X_test_statistics_mitbih['fft_median'] = fft.median(axis=1)\n",
    "\n",
    "# FFT median absolute deviation features, don't use fft.mad(axis=1) because it's the average absolute difference\n",
    "# X_test_statistics_mitbih['fft_median_abs_dev'] = (fft - X_test_statistics_mitbih['fft_median']).abs().median(axis=1)\n",
    "\n",
    "# FFT interquartile range features\n",
    "X_test_statistics_mitbih['fft_interquartile_range'] = fft.quantile(0.75, axis=1) - fft.quantile(0.25, axis=1)\n",
    "\n",
    "# FFT values above mean features\n",
    "# X_test_statistics_mitbih['fft_values_above_mean'] = (fft > X_test_statistics_mitbih['fft_mean']).sum(axis=1)\n",
    "\n",
    "# FFT number of peaks features\n",
    "# X_test_statistics_mitbih['fft_number_of_peaks'] = (fft.diff(axis=1) < 0).sum(axis=1)\n",
    "\n",
    "# FFT skewnness features\n",
    "X_test_statistics_mitbih['fft_skewness'] = fft.skew(axis=1)\n",
    "\n",
    "# FFT kurtosis features\n",
    "X_test_statistics_mitbih['fft_kurtosis'] = fft.kurtosis(axis=1)\n",
    "\n",
    "# FFT energy features\n",
    "X_test_statistics_mitbih['fft_energy'] = (fft ** 2).sum(axis=1)\n",
    "\n",
    "# FFT average of absolute values features\n",
    "X_test_statistics_mitbih['fft_avg_abs_val'] = fft.abs().mean(axis=1)\n",
    "\n",
    "# FFT signal magnitude area features\n",
    "X_test_statistics_mitbih['fft_signal_magnitude_area'] = fft.abs().sum(axis=1)\n",
    "\n",
    "X_test_statistics_mitbih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setam atributele statistice date de intrare ptbdb pentru datele de test\n",
    "X_test_statistics_ptbdb = pd.DataFrame()\n",
    "\n",
    "# Mean features\n",
    "X_test_statistics_ptbdb['mean'] = X_test_std_ptbdb.mean(axis=1)\n",
    "\n",
    "# Standard deviation features\n",
    "X_test_statistics_ptbdb['std'] = X_test_std_ptbdb.std(axis=1)\n",
    "\n",
    "# Average absolute difference features\n",
    "X_test_statistics_ptbdb['avg_abs_diff'] = X_test_std_ptbdb.mad(axis=1)\n",
    "\n",
    "# Min features\n",
    "X_test_statistics_ptbdb['min'] = X_test_std_ptbdb.min(axis=1)\n",
    "\n",
    "# Max features\n",
    "X_test_statistics_ptbdb['max'] = X_test_std_ptbdb.max(axis=1)\n",
    "\n",
    "# Max-min features\n",
    "X_test_statistics_ptbdb['max-min'] = X_test_statistics_ptbdb['max'] - X_test_statistics_ptbdb['min']\n",
    "\n",
    "# Median features\n",
    "X_test_statistics_ptbdb['median'] = X_test_std_ptbdb.median(axis=1)\n",
    "\n",
    "# Median absolute deviation features, don't use X_test_std_ptbdb.mad(axis=1) because it's the average absolute difference\n",
    "# X_test_statistics_ptbdb['median_abs_dev'] = (X_test_std_ptbdb - X_test_statistics_ptbdb['median']).abs().median(axis=1)\n",
    "\n",
    "# Interquartile range features\n",
    "X_test_statistics_ptbdb['interquartile_range'] = X_test_std_ptbdb.quantile(0.75, axis=1) - X_test_std_ptbdb.quantile(0.25, axis=1)\n",
    "\n",
    "# Values above mean features\n",
    "# X_test_statistics_ptbdb['values_above_mean'] = (X_test_std_ptbdb > X_test_statistics_ptbdb['mean']).sum(axis=1)\n",
    "\n",
    "# Number of peaks features\n",
    "# X_test_statistics_ptbdb['number_of_peaks'] = (X_test_std_ptbdb.diff(axis=1) < 0).sum(axis=1)\n",
    "\n",
    "# Skewnness features\n",
    "X_test_statistics_ptbdb['skewness'] = X_test_std_ptbdb.skew(axis=1)\n",
    "\n",
    "# Kurtosis features\n",
    "X_test_statistics_ptbdb['kurtosis'] = X_test_std_ptbdb.kurtosis(axis=1)\n",
    "\n",
    "# Energy features\n",
    "X_test_statistics_ptbdb['energy'] = (X_test_std_ptbdb ** 2).sum(axis=1)\n",
    "\n",
    "# Average of absolute values features\n",
    "X_test_statistics_ptbdb['avg_abs_val'] = X_test_std_ptbdb.abs().mean(axis=1)\n",
    "\n",
    "# Signal magnitude area features\n",
    "X_test_statistics_ptbdb['signal_magnitude_area'] = X_test_std_ptbdb.abs().sum(axis=1)\n",
    "\n",
    "# Compute FFT features\n",
    "fft = np.abs(np.fft.fft(X_test_std_ptbdb))\n",
    "\n",
    "# make fft data frame\n",
    "fft = pd.DataFrame(fft)\n",
    "\n",
    "# FFT mean features\n",
    "X_test_statistics_ptbdb['fft_mean'] = fft.mean(axis=1)\n",
    "\n",
    "# FFT standard deviation features\n",
    "X_test_statistics_ptbdb['fft_std'] = fft.std(axis=1)\n",
    "\n",
    "# FFT average absolute difference features\n",
    "X_test_statistics_ptbdb['fft_avg_abs_diff'] = fft.mad(axis=1)\n",
    "\n",
    "# FFT min features\n",
    "X_test_statistics_ptbdb['fft_min'] = fft.min(axis=1)\n",
    "\n",
    "# FFT max features\n",
    "X_test_statistics_ptbdb['fft_max'] = fft.max(axis=1)\n",
    "\n",
    "# FFT max-min features\n",
    "X_test_statistics_ptbdb['fft_max-min'] = X_test_statistics_ptbdb['fft_max'] - X_test_statistics_ptbdb['fft_min']\n",
    "\n",
    "# FFT median features\n",
    "X_test_statistics_ptbdb['fft_median'] = fft.median(axis=1)\n",
    "\n",
    "# FFT median absolute deviation features, don't use fft.mad(axis=1) because it's the average absolute difference\n",
    "# X_test_statistics_ptbdb['fft_median_abs_dev'] = (fft - X_test_statistics_ptbdb['fft_median']).abs().median(axis=1)\n",
    "\n",
    "# FFT interquartile range features\n",
    "X_test_statistics_ptbdb['fft_interquartile_range'] = fft.quantile(0.75, axis=1) - fft.quantile(0.25, axis=1)\n",
    "\n",
    "# FFT values above mean features\n",
    "# X_test_statistics_ptbdb['fft_values_above_mean'] = (fft > X_test_statistics_ptbdb['fft_mean']).sum(axis=1)\n",
    "\n",
    "# FFT number of peaks features\n",
    "# X_test_statistics_ptbdb['fft_number_of_peaks'] = (fft.diff(axis=1) < 0).sum(axis=1)\n",
    "\n",
    "# FFT skewnness features\n",
    "X_test_statistics_ptbdb['fft_skewness'] = fft.skew(axis=1)\n",
    "\n",
    "# FFT kurtosis features\n",
    "X_test_statistics_ptbdb['fft_kurtosis'] = fft.kurtosis(axis=1)\n",
    "\n",
    "# FFT energy features\n",
    "X_test_statistics_ptbdb['fft_energy'] = (fft ** 2).sum(axis=1)\n",
    "\n",
    "# FFT average of absolute values features\n",
    "X_test_statistics_ptbdb['fft_avg_abs_val'] = fft.abs().mean(axis=1)\n",
    "\n",
    "# FFT signal magnitude area features\n",
    "X_test_statistics_ptbdb['fft_signal_magnitude_area'] = fft.abs().sum(axis=1)\n",
    "\n",
    "X_test_statistics_ptbdb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with standard parameters MITBIH\n",
    "svm_std_parameters_mitbih = SVC()\n",
    "svm_std_parameters_mitbih.fit(X_train_std_mitbih, train_y_mitbih)\n",
    "\n",
    "# print prediction results\n",
    "predictions = svm_std_parameters_mitbih.predict(X_test_std_mitbih)\n",
    "print(classification_report(test_y_mitbih, predictions))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "           precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.97      1.00      0.98     18118\n",
    "         1.0       0.96      0.56      0.71       556\n",
    "         2.0       0.97      0.86      0.91      1448\n",
    "         3.0       0.75      0.48      0.59       162\n",
    "         4.0       1.00      0.91      0.95      1608\n",
    "\n",
    "    accuracy                           0.97     21892\n",
    "   macro avg       0.93      0.76      0.83     21892\n",
    "weighted avg       0.97      0.97      0.97     21892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with standard parameters PTBDB\n",
    "svm_std_parameters_ptbdb = SVC()\n",
    "svm_std_parameters_ptbdb.fit(X_train_std_ptbdb, train_y_ptbdb)\n",
    "\n",
    "# print prediction results\n",
    "predictions = svm_std_parameters_ptbdb.predict(X_test_std_ptbdb)\n",
    "print(classification_report(test_y_ptbdb, predictions))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "             precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.85      0.78      0.81      1349\n",
    "         1.0       0.92      0.95      0.93      3454\n",
    "\n",
    "    accuracy                           0.90      4803\n",
    "   macro avg       0.88      0.86      0.87      4803\n",
    "weighted avg       0.90      0.90      0.90      4803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Threshold\n",
    "VARIANCE_THRESHOLD = 0\n",
    "SELECT_PERCENTILE = 90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=VARIANCE_THRESHOLD)\n",
    "\n",
    "# Variance Threshold PTBDB \n",
    "X_train_variance_ptbdb = X_train_std_ptbdb.copy()\n",
    "X_test_variance_ptbdb = X_test_std_ptbdb.copy()\n",
    "\n",
    "sel.fit_transform(X_train_variance_ptbdb)\n",
    "sel.fit_transform(X_test_variance_ptbdb)\n",
    "\n",
    "# transform X_train to ndarray\n",
    "X_train_variance_ptbdb = sel.transform(X_train_variance_ptbdb)\n",
    "X_test_variance_ptbdb = sel.transform(X_test_variance_ptbdb)\n",
    "\n",
    "print(X_test_variance_ptbdb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=VARIANCE_THRESHOLD)\n",
    "\n",
    "# Variance Threshold MITBIH \n",
    "X_train_variance_mitbih = X_train_std_mitbih.copy()\n",
    "X_test_variance_mitbih = X_test_std_mitbih.copy()\n",
    "\n",
    "sel.fit_transform(X_train_variance_mitbih)\n",
    "sel.fit_transform(X_test_variance_mitbih)\n",
    "\n",
    "# transform X_train to ndarray\n",
    "X_train_variance_mitbih = sel.transform(X_train_variance_mitbih)\n",
    "X_test_variance_mitbih = sel.transform(X_test_variance_mitbih)\n",
    "\n",
    "print(X_test_variance_mitbih.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "# Select Percentile PTBDB\n",
    "X_train_percentile_ptbdb = X_train_std_ptbdb.copy()\n",
    "\n",
    "X_test_percentile_ptbdb = X_test_std_ptbdb.copy()\n",
    "\n",
    "# add columns name to X_test_percentile x1, x2, x3, , xn\n",
    "X_test_percentile_ptbdb.columns = [f'x{i}' for i in range(1, X_test_percentile_ptbdb.shape[1] + 1)]\n",
    "\n",
    "# add columns name to X_train_percentile x1, x2, x3, , xn\n",
    "X_train_percentile_ptbdb.columns = [f'x{i}' for i in range(1, X_train_percentile_ptbdb.shape[1] + 1)]\n",
    "\n",
    "X_train_percentile_ptbdb = SelectPercentile(percentile=SELECT_PERCENTILE).fit(X_train_percentile_ptbdb, train_y_ptbdb)\n",
    "\n",
    "train_features_names_ptbdb = X_train_percentile_ptbdb.get_feature_names_out()\n",
    "\n",
    "X_train_percentile_ptbdb = X_train_percentile_ptbdb.transform(X_train_std_ptbdb)\n",
    "\n",
    "# Remove features using SelectPercentile from X_test_percentile using the same features\n",
    "X_test_percentile_ptbdb = X_test_percentile_ptbdb[train_features_names_ptbdb]\n",
    "\n",
    "print(X_train_percentile_ptbdb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Percentile mitbih\n",
    "X_train_percentile_mitbih = X_train_std_mitbih.copy()\n",
    "\n",
    "X_test_percentile_mitbih = X_test_std_mitbih.copy()\n",
    "\n",
    "# add columns name to X_test_percentile x1, x2, x3, , xn\n",
    "X_test_percentile_mitbih.columns = [f'x{i}' for i in range(1, X_test_percentile_mitbih.shape[1] + 1)]\n",
    "\n",
    "# add columns name to X_train_percentile x1, x2, x3, , xn\n",
    "X_train_percentile_mitbih.columns = [f'x{i}' for i in range(1, X_train_percentile_mitbih.shape[1] + 1)]\n",
    "\n",
    "X_train_percentile_mitbih = SelectPercentile(percentile=SELECT_PERCENTILE).fit(X_train_percentile_mitbih, train_y_mitbih)\n",
    "\n",
    "train_features_names_mitbih = X_train_percentile_mitbih.get_feature_names_out()\n",
    "\n",
    "X_train_percentile_mitbih = X_train_percentile_mitbih.transform(X_train_std_mitbih)\n",
    "\n",
    "# Remove features using SelectPercentile from X_test_percentile using the same features\n",
    "X_test_percentile_mitbih = X_test_percentile_mitbih[train_features_names_mitbih]\n",
    "\n",
    "print(X_train_percentile_mitbih)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with standard parameters MITBIH with variance threshold\n",
    "svm_std_parameters_mitbih_variance = SVC()\n",
    "svm_std_parameters_mitbih_variance.fit(X_train_variance_mitbih, train_y_mitbih)\n",
    "\n",
    "# print prediction results\n",
    "predictions = svm_std_parameters_mitbih_variance.predict(X_test_variance_mitbih)\n",
    "\n",
    "print(classification_report(test_y_mitbih, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VARIANCE 0\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.97      1.00      0.98     18118\n",
    "         1.0       0.96      0.56      0.71       556\n",
    "         2.0       0.97      0.86      0.91      1448\n",
    "         3.0       0.75      0.48      0.59       162\n",
    "         4.0       1.00      0.91      0.95      1608\n",
    "\n",
    "    accuracy                           0.97     21892\n",
    "   macro avg       0.93      0.76      0.83     21892\n",
    "weighted avg       0.97      0.97      0.97     21892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with standard parameters PTBDB with variance threshold\n",
    "svm_std_parameters_ptbdb_variance = SVC()\n",
    "svm_std_parameters_ptbdb_variance.fit(X_train_variance_ptbdb, train_y_ptbdb)\n",
    "\n",
    "# print prediction results\n",
    "predictions = svm_std_parameters_ptbdb_variance.predict(X_test_variance_ptbdb)\n",
    "\n",
    "print(classification_report(test_y_ptbdb, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VARIANCE 0\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.85      0.78      0.81      1349\n",
    "         1.0       0.92      0.95      0.93      3454\n",
    "\n",
    "    accuracy                           0.90      4803\n",
    "   macro avg       0.88      0.86      0.87      4803\n",
    "weighted avg       0.90      0.90      0.90      4803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with standard parameters MITBIH with percentile threshold\n",
    "svm_std_parameters_mitbih_percentile = SVC()\n",
    "svm_std_parameters_mitbih_percentile.fit(X_train_percentile_mitbih, train_y_mitbih)\n",
    "\n",
    "# print prediction results\n",
    "predictions = svm_std_parameters_mitbih_percentile.predict(X_test_percentile_mitbih)\n",
    "\n",
    "print(classification_report(test_y_mitbih, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERCENTILE 70\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.97      1.00      0.98     18118\n",
    "         1.0       0.97      0.56      0.71       556\n",
    "         2.0       0.96      0.88      0.92      1448\n",
    "         3.0       0.80      0.53      0.64       162\n",
    "         4.0       1.00      0.90      0.95      1608\n",
    "\n",
    "    accuracy                           0.97     21892\n",
    "   macro avg       0.94      0.77      0.84     21892\n",
    "weighted avg       0.97      0.97      0.97     21892"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERCENTILE 30\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.96      1.00      0.98     18118\n",
    "         1.0       0.95      0.55      0.70       556\n",
    "         2.0       0.95      0.80      0.87      1448\n",
    "         3.0       0.92      0.28      0.43       162\n",
    "         4.0       1.00      0.90      0.94      1608\n",
    "\n",
    "    accuracy                           0.96     21892\n",
    "   macro avg       0.95      0.71      0.78     21892\n",
    "weighted avg       0.96      0.96      0.96     21892"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERCENTILE 10\n",
    "\n",
    "            precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.94      0.99      0.97     18118\n",
    "         1.0       0.84      0.51      0.63       556\n",
    "         2.0       0.94      0.60      0.73      1448\n",
    "         3.0       0.88      0.04      0.08       162\n",
    "         4.0       0.97      0.86      0.91      1608\n",
    "\n",
    "    accuracy                           0.94     21892\n",
    "   macro avg       0.91      0.60      0.66     21892\n",
    "weighted avg       0.94      0.94      0.93     21892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with standard parameters PTBDB with percentile threshold\n",
    "svm_std_parameters_ptbdb_percentile = SVC()\n",
    "\n",
    "svm_std_parameters_ptbdb_percentile.fit(X_train_percentile_ptbdb, train_y_ptbdb)\n",
    "\n",
    "# print prediction results\n",
    "predictions = svm_std_parameters_ptbdb_percentile.predict(X_test_percentile_ptbdb)\n",
    "\n",
    "print(classification_report(test_y_ptbdb, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERCENTILE 70\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.83      0.79      0.81      1349\n",
    "         1.0       0.92      0.94      0.93      3454\n",
    "\n",
    "    accuracy                           0.90      4803\n",
    "   macro avg       0.88      0.86      0.87      4803\n",
    "weighted avg       0.90      0.90      0.90      4803\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERCENTILE 30\n",
    "\n",
    "            precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.80      0.60      0.68      1349\n",
    "         1.0       0.86      0.94      0.90      3454\n",
    "\n",
    "    accuracy                           0.84      4803\n",
    "   macro avg       0.83      0.77      0.79      4803\n",
    "weighted avg       0.84      0.84      0.84      4803"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERCENTILE 10\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.74      0.44      0.55      1349\n",
    "         1.0       0.81      0.94      0.87      3454\n",
    "\n",
    "    accuracy                           0.80      4803\n",
    "   macro avg       0.78      0.69      0.71      4803\n",
    "weighted avg       0.79      0.80      0.78      4803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001],\n",
    "              'kernel': ['rbf', 'poly', 'sigmoid']} \n",
    "\n",
    "CV = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with GridSearchCV MITBIH with all features\n",
    "\n",
    "svm_model_all_features_mitbih = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "\n",
    "svm_model_all_features_mitbih.fit(X_train_std_mitbih, train_y_mitbih)\n",
    "\n",
    "print(svm_model_all_features_mitbih.best_params_)\n",
    "\n",
    "# print prediction results\n",
    "predictions = svm_model_all_features_mitbih.predict(X_test_std_mitbih)\n",
    "\n",
    "print(classification_report(test_y_mitbih, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with GridSearchCV PTBDB with all features\n",
    "\n",
    "svm_model_all_features_ptbdb = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, cv=CV)\n",
    "\n",
    "svm_model_all_features_ptbdb.fit(X_train_std_ptbdb, train_y_ptbdb)\n",
    "\n",
    "print(svm_model_all_features_ptbdb.best_params_)\n",
    "\n",
    "# print prediction results\n",
    "predictions = svm_model_all_features_ptbdb.predict(X_test_std_ptbdb)\n",
    "\n",
    "print(classification_report(test_y_ptbdb, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.97      0.93      0.95      1349\n",
    "         1.0       0.97      0.99      0.98      3454\n",
    "\n",
    "    accuracy                           0.97      4803\n",
    "   macro avg       0.97      0.96      0.96      4803\n",
    "weighted avg       0.97      0.97      0.97      4803\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM   with GridSearchCV MITBIH with variance threshold\n",
    "\n",
    "svm_model_variance_mitbih = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, cv=CV)\n",
    "\n",
    "svm_model_variance_mitbih.fit(X_train_variance_mitbih, train_y_mitbih)\n",
    "\n",
    "print(svm_model_variance_mitbih.best_params_)\n",
    "\n",
    "# print prediction results\n",
    "predictions = svm_model_variance_mitbih.predict(X_test_variance_mitbih)\n",
    "\n",
    "print(classification_report(test_y_mitbih, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with GridSearchCV PTBDB with variance threshold\n",
    "\n",
    "svm_model_variance_ptbdb = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, cv=CV)\n",
    "\n",
    "svm_model_variance_ptbdb.fit(X_train_variance_ptbdb, train_y_ptbdb)\n",
    "\n",
    "print(svm_model_variance_ptbdb.best_params_)\n",
    "\n",
    "# print prediction results\n",
    "\n",
    "predictions = svm_model_variance_ptbdb.predict(X_test_variance_ptbdb)\n",
    "\n",
    "print(classification_report(test_y_ptbdb, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.97      0.93      0.95      1349\n",
    "         1.0       0.97      0.99      0.98      3454\n",
    "\n",
    "    accuracy                           0.97      4803\n",
    "   macro avg       0.97      0.96      0.96      4803\n",
    "weighted avg       0.97      0.97      0.97      4803\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with GridSearchCV MITBIH with percentile threshold\n",
    "\n",
    "svm_model_percentile_mitbih = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "\n",
    "svm_model_percentile_mitbih.fit(X_train_percentile_mitbih, train_y_mitbih)\n",
    "\n",
    "print(svm_model_percentile_mitbih.best_params_)\n",
    "\n",
    "# print prediction results\n",
    "\n",
    "predictions = svm_model_percentile_mitbih.predict(X_test_percentile_mitbih)\n",
    "\n",
    "print(classification_report(test_y_mitbih, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with GridSearchCV PTBDB with percentile threshold\n",
    "\n",
    "svm_model_percentile_ptbdb = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, cv=CV)\n",
    "\n",
    "svm_model_percentile_ptbdb.fit(X_train_percentile_ptbdb, train_y_ptbdb)\n",
    "\n",
    "print(svm_model_percentile_ptbdb.best_params_)\n",
    "\n",
    "# print prediction results\n",
    "\n",
    "predictions = svm_model_percentile_ptbdb.predict(X_test_percentile_ptbdb)\n",
    "\n",
    "print(classification_report(test_y_ptbdb, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERCENTILE 90\n",
    "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
    "\n",
    "           precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.97      0.93      0.95      1349\n",
    "         1.0       0.97      0.99      0.98      3454\n",
    "\n",
    "    accuracy                           0.97      4803\n",
    "   macro avg       0.97      0.96      0.96      4803\n",
    "weighted avg       0.97      0.97      0.97      4803\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERCENTILE 70\n",
    "\n",
    "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.96      0.93      0.94      1349\n",
    "         1.0       0.97      0.98      0.98      3454\n",
    "\n",
    "    accuracy                           0.97      4803\n",
    "   macro avg       0.97      0.96      0.96      4803\n",
    "weighted avg       0.97      0.97      0.97      4803"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERCENTILE 30\n",
    "\n",
    "{'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n",
    "           precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.92      0.91      0.92      1349\n",
    "         1.0       0.97      0.97      0.97      3454\n",
    "\n",
    "    accuracy                           0.95      4803\n",
    "   macro avg       0.94      0.94      0.94      4803\n",
    "weighted avg       0.95      0.95      0.95      4803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with standard parameters MITBIH with all features\n",
    "\n",
    "rf_std_parameters_mitbih = RandomForestClassifier()\n",
    "\n",
    "rf_std_parameters_mitbih.fit(X_train_std_mitbih, train_y_mitbih)\n",
    "\n",
    "# print prediction results\n",
    "predictions = rf_std_parameters_mitbih.predict(X_test_std_mitbih)\n",
    "\n",
    "print(classification_report(test_y_mitbih, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with standard parameters PTBDB with all features\n",
    "\n",
    "rf_std_parameters_ptbdb = RandomForestClassifier()\n",
    "\n",
    "rf_std_parameters_ptbdb.fit(X_train_std_ptbdb, train_y_ptbdb)\n",
    "\n",
    "# print prediction results\n",
    "predictions = rf_std_parameters_ptbdb.predict(X_test_std_ptbdb)\n",
    "\n",
    "print(classification_report(test_y_ptbdb, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.97      0.92      0.94      1349\n",
    "         1.0       0.97      0.99      0.98      3454\n",
    "\n",
    "    accuracy                           0.97      4803\n",
    "   macro avg       0.97      0.95      0.96      4803\n",
    "weighted avg       0.97      0.97      0.97      4803\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with standard parameters MITBIH with variance threshold\n",
    "\n",
    "rf_std_parameters_mitbih_variance = RandomForestClassifier()\n",
    "\n",
    "rf_std_parameters_mitbih_variance.fit(X_train_variance_mitbih, train_y_mitbih)\n",
    "\n",
    "# print prediction results\n",
    "\n",
    "predictions = rf_std_parameters_mitbih_variance.predict(X_test_variance_mitbih)\n",
    "\n",
    "print(classification_report(test_y_mitbih, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with standard parameters PTBDB with variance threshold\n",
    "\n",
    "rf_std_parameters_ptbdb_variance = RandomForestClassifier()\n",
    "\n",
    "rf_std_parameters_ptbdb_variance.fit(X_train_variance_ptbdb, train_y_ptbdb)\n",
    "\n",
    "# print prediction results\n",
    "\n",
    "predictions = rf_std_parameters_ptbdb_variance.predict(X_test_variance_ptbdb)\n",
    "\n",
    "print(classification_report(test_y_ptbdb, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.96      0.92      0.94      1349\n",
    "         1.0       0.97      0.99      0.98      3454\n",
    "\n",
    "    accuracy                           0.97      4803\n",
    "   macro avg       0.97      0.95      0.96      4803\n",
    "weighted avg       0.97      0.97      0.97      4803\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with standard parameters MITBIH with percentile threshold\n",
    "\n",
    "rf_std_parameters_mitbih_percentile = RandomForestClassifier()\n",
    "\n",
    "rf_std_parameters_mitbih_percentile.fit(X_train_percentile_mitbih, train_y_mitbih)\n",
    "\n",
    "# print prediction results\n",
    "\n",
    "predictions = rf_std_parameters_mitbih_percentile.predict(X_test_percentile_mitbih)\n",
    "\n",
    "print(classification_report(test_y_mitbih, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with standard parameters PTBDB with percentile threshold\n",
    "\n",
    "rf_std_parameters_ptbdb_percentile = RandomForestClassifier()\n",
    "\n",
    "rf_std_parameters_ptbdb_percentile.fit(X_train_percentile_ptbdb, train_y_ptbdb)\n",
    "\n",
    "# print prediction results\n",
    "\n",
    "predictions = rf_std_parameters_ptbdb_percentile.predict(X_test_percentile_ptbdb)\n",
    "\n",
    "print(classification_report(test_y_ptbdb, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERCENTILE 90\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.97      0.91      0.94      1349\n",
    "         1.0       0.97      0.99      0.98      3454\n",
    "\n",
    "    accuracy                           0.97      4803\n",
    "   macro avg       0.97      0.95      0.96      4803\n",
    "weighted avg       0.97      0.97      0.97      4803"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERCENTILE 70\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.97      0.91      0.94      1349\n",
    "         1.0       0.96      0.99      0.98      3454\n",
    "\n",
    "    accuracy                           0.97      4803\n",
    "   macro avg       0.97      0.95      0.96      4803\n",
    "weighted avg       0.97      0.97      0.97      4803"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERCENTILE 30\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.94      0.82      0.88      1349\n",
    "         1.0       0.93      0.98      0.96      3454\n",
    "\n",
    "    accuracy                           0.93      4803\n",
    "   macro avg       0.94      0.90      0.92      4803\n",
    "weighted avg       0.93      0.93      0.93      4803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [100, 200, 300, 400],\n",
    "                'max_features': ['sqrt', 'log2'],\n",
    "                'max_depth' : [5,6,7],\n",
    "                'criterion' :['gini', 'entropy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with GridSearchCV MITBIH with all features\n",
    "\n",
    "rf_model_all_features_mitbih = GridSearchCV(RandomForestClassifier(), param_grid, refit = True, verbose = 3, cv=CV)\n",
    "\n",
    "rf_model_all_features_mitbih.fit(X_train_std_mitbih, train_y_mitbih)\n",
    "\n",
    "print(rf_model_all_features_mitbih.best_params_)\n",
    "\n",
    "# print prediction results\n",
    "\n",
    "predictions = rf_model_all_features_mitbih.predict(X_test_std_mitbih)\n",
    "\n",
    "print(classification_report(test_y_mitbih, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with GridSearchCV PTBDB with all features\n",
    "\n",
    "rf_model_all_features_ptbdb = GridSearchCV(RandomForestClassifier(), param_grid, refit = True, verbose = 3, cv=CV)\n",
    "\n",
    "rf_model_all_features_ptbdb.fit(X_train_std_ptbdb, train_y_ptbdb)\n",
    "\n",
    "print(rf_model_all_features_ptbdb.best_params_)\n",
    "\n",
    "# print prediction results\n",
    "\n",
    "predictions = rf_model_all_features_ptbdb.predict(X_test_std_ptbdb)\n",
    "\n",
    "print(classification_report(test_y_ptbdb, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.84      0.84      0.84      1349\n",
    "         1.0       0.94      0.94      0.94      3454\n",
    "\n",
    "    accuracy                           0.91      4803\n",
    "   macro avg       0.89      0.89      0.89      4803\n",
    "weighted avg       0.91      0.91      0.91      4803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with GridSearchCV MITBIH with variance threshold\n",
    "\n",
    "rf_model_variance_mitbih = GridSearchCV(RandomForestClassifier(), param_grid, refit = True, verbose = 3, cv=CV)\n",
    "\n",
    "rf_model_variance_mitbih.fit(X_train_variance_mitbih, train_y_mitbih)\n",
    "\n",
    "print(rf_model_variance_mitbih.best_params_)\n",
    "\n",
    "# print prediction results\n",
    "\n",
    "predictions = rf_model_variance_mitbih.predict(X_test_variance_mitbih)\n",
    "\n",
    "print(classification_report(test_y_mitbih, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with GridSearchCV PTBDB with variance threshold\n",
    "\n",
    "rf_model_variance_ptbdb = GridSearchCV(RandomForestClassifier(), param_grid, refit = True, verbose = 3, cv=CV)\n",
    "\n",
    "rf_model_variance_ptbdb.fit(X_train_variance_ptbdb, train_y_ptbdb)\n",
    "\n",
    "print(rf_model_variance_ptbdb.best_params_)\n",
    "\n",
    "# print prediction results\n",
    "\n",
    "predictions = rf_model_variance_ptbdb.predict(X_test_variance_ptbdb)\n",
    "\n",
    "print(classification_report(test_y_ptbdb, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Random Forest with GridSearchCV MITBIH with percentile threshold\u001b[39;00m\n\u001b[0;32m      3\u001b[0m rf_model_percentile_mitbih \u001b[39m=\u001b[39m GridSearchCV(RandomForestClassifier(), param_grid, refit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, verbose \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m rf_model_percentile_mitbih\u001b[39m.\u001b[39;49mfit(X_train_percentile_mitbih, train_y_mitbih)\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(rf_model_percentile_mitbih\u001b[39m.\u001b[39mbest_params_)\n\u001b[0;32m      9\u001b[0m \u001b[39m# print prediction results\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    477\u001b[0m )(\n\u001b[0;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    479\u001b[0m         t,\n\u001b[0;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    481\u001b[0m         X,\n\u001b[0;32m    482\u001b[0m         y,\n\u001b[0;32m    483\u001b[0m         sample_weight,\n\u001b[0;32m    484\u001b[0m         i,\n\u001b[0;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Random Forest with GridSearchCV MITBIH with percentile threshold\n",
    "\n",
    "rf_model_percentile_mitbih = GridSearchCV(RandomForestClassifier(), param_grid, refit = True, verbose = 3, cv=2)\n",
    "\n",
    "rf_model_percentile_mitbih.fit(X_train_percentile_mitbih, train_y_mitbih)\n",
    "\n",
    "print(rf_model_percentile_mitbih.best_params_)\n",
    "\n",
    "# print prediction results\n",
    "\n",
    "predictions = rf_model_percentile_mitbih.predict(X_test_percentile_mitbih)\n",
    "\n",
    "print(classification_report(test_y_mitbih, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with GridSearchCV PTBDB with percentile threshold\n",
    "\n",
    "rf_model_percentile_ptbdb = GridSearchCV(RandomForestClassifier(), param_grid, refit = True, verbose = 3, cv=CV)\n",
    "\n",
    "rf_model_percentile_ptbdb.fit(X_train_percentile_ptbdb, train_y_ptbdb)\n",
    "\n",
    "print(rf_model_percentile_ptbdb.best_params_)\n",
    "\n",
    "# print prediction results\n",
    "\n",
    "predictions = rf_model_percentile_ptbdb.predict(X_test_percentile_ptbdb)\n",
    "\n",
    "\n",
    "print(classification_report(test_y_ptbdb, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERCENTILE 90\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.84      0.84      0.84      1349\n",
    "         1.0       0.94      0.94      0.94      3454\n",
    "\n",
    "    accuracy                           0.91      4803\n",
    "   macro avg       0.89      0.89      0.89      4803\n",
    "weighted avg       0.91      0.91      0.91      4803"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERCENTILE 30\n",
    "\n",
    "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.87      0.70      0.77      1349\n",
    "         1.0       0.89      0.96      0.92      3454\n",
    "\n",
    "    accuracy                           0.89      4803\n",
    "   macro avg       0.88      0.83      0.85      4803\n",
    "weighted avg       0.88      0.89      0.88      4803\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERCENTILE 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pot seta pe cat % din date sa fie antrenat random shuffle 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting with standard parameters PTBDB with all features\n",
    "\n",
    "gbt_std_parameters_ptbdb = GradientBoostingClassifier()\n",
    "\n",
    "gbt_std_parameters_ptbdb.fit(X_train_std_ptbdb, train_y_mitbih)\n",
    "\n",
    "predictions = gbt_std_parameters_ptbdb.predict(X_test_std_ptbdb)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
